<!doctype book PUBLIC "-//Davenport//DTD DocBook V3.0//EN" [
<!entity  the-index SYSTEM "genindex.sgml">
]>

<book>
  <bookinfo>
    <date>1999-9-17</date>
    <title>Happy User Guide</title>
    <author>
      <firstname>Simon</firstname>
      <surname>Marlow</surname>
    </author>
    <author>
      <firstname>Andy</firstname>
      <surname>Gill</surname>
    </author>
    <address><email>simonmar@microsoft.com</email></address>
    <copyright>
      <year>1997-1999</year>
      <holder>Simon Marlow</holder>
    </copyright>
    <abstract>
      <para>This document describes Happy, the Haskell Parser
	Generator, version 1.6.</para>
    </abstract>
  </bookinfo>

  <!-- Table of contents -->
  <toc></toc>
  
<!-- Introduction --------------------------------------------------------- -->

  <chapter>
    <title>Introduction</title>


    <para> <application/Happy/ is a parser generator system for
    Haskell, similar to the tool <application/yacc/for C.  Like
    <application/yacc/, it takes a file containing an annotated BNF
    specification of a grammar and produces a Haskell module
    containing a parser for the grammar. </para>
    
    <indexterm><primary>yacc</primary></indexterm>

    <para> <application/Happy/ is flexible; unlike <application/yacc/,
    you can have several <application/Happy/ parsers in the same
    program.  <application/Happy/ can work in conjunction with a
    lexical analyser supplied by the user (either hand-written or
    generated by another program), or it can parse a stream of
    characters directly (but this isn't practical in most cases).  In
    a future version we hope to include a lexical analyser generator
    with <application/Happy/ as a single package. </para>

    <para> Parsers generated by <application/Happy/ are fast;
    generally faster than an equivalent parser written using parsing
    combinators or similar tools.  Furthermore, any future
    improvements made to <application/Happy/ will benefit an existing
    grammar, without need for a rewrite. </para>

    <para> <application/Happy/ is sufficiently powerful to parse
    Haskell itself - there's a freely available Haskell parser written
    using <application/Happy/ which can be obtained from <ulink
    url="http://www.pms.informatik.uni-muenchen.de/mitarbeiter/panne/haskell_libs/hsparser.html">
    The <literal/hsparser/ Page</ulink>. </para>

    <indexterm><primary><literal/hsparser/</primary></indexterm>
    <indexterm>
      <primary>Haskell parser</primary>
      <see><literal/hsparser/</see>
    </indexterm>

    <para> <application/Happy/ can currently generate three types of
    parser from a given grammar, the intention being that we can
    experiment with different kinds of functional code to see which is
    the best, and compiler writers can use the different types of
    parser to tune their compilers.  The types of parser supported
    are: </para>
    
    <orderedlist>
      
      <listitem id="item-default-backend"> <para>`standard' Haskell 98
      (should work with any compiler that compiles Haskell
      98).</para></listitem>
      
      <listitem> <para>standard Haskell using arrays
      <indexterm scope="all">
	    <primary>arrays</primary>
	  </indexterm>
      <indexterm scope="all">
	    <primary>back-ends</primary>
	    <secondary>arrays</secondary>
	  </indexterm>
      (this is not the default because we have
      found this generates slower parsers than <xref
      linkend="item-default-backend">).</para></listitem>

      <listitem> <para>Haskell with GHC (Glasgow Haskell) extensions.
      This is a slightly faster option than <xref
      linkend="item-default-backend"> for Glasgow Haskell
      users.</para></listitem>

      <indexterm>
	<primary>ghc</primary>
      </indexterm>

      <indexterm>
	<primary>back-ends</primary>
	<secondary>ghc</secondary>
      </indexterm>
    </orderedlist>

    <sect1 id="sec-compatibility">
      <title>Compatibility</title>

      <para> <application/Happy/ is written in Haskell 98. This means
      that it will compile under <application/Glasgow Haskell/
      (recommended), <application/hbc/, <application/Hugs/, and any
      other Haskell 98 compiler.
      </para>

      <para> Remember: parsers produced using <application/Happy/
      should compile happily (sic) under any Haskell 98 complier.  A
      compatibility mode enables <application/Happy/ to generate
      parsers that will compile with a Haskell 1.2 compiler, such as
      <application/GHC 0.29/.  </para>

    </sect1>

    <sect1 id="sec-reporting-bugs">
      <title>Reporting Bugs</title>

      <indexterm>
	<primary>bugs, reporting</primary>
      </indexterm>

      <para> Any bugs found in <application/Happy/ should be reported
      to me: Simon Marlow <email>simonmar@microsoft.com</email>
      including all the relevant information: - the compiler used to
      compile <application/Happy/, the command-line options used, your
      grammar file or a cut-down example showing the problem, and a
      description of what goes wrong.  A patch to fix the problem
      would also be greatly appreciated. </para>

      <para> Requests for new features should also be sent to the
      above address, especially if accompanied by patches.  You never
      know, if I get another request to implement yacc-style
      precedences, I might just do it :-) </para>

    </sect1>

    <sect1 id="sec-license">
      <title>License</title>

      <indexterm>
	<primary>License</primary>
      </indexterm>

      <para> Previous versions of <application/Happy/ were covered by
      the GNU general public license.  We're now distributing
      <application/Happy/ with a less restrictive BSD-style
      license:</para>
      
      <blockquote>
	<para> Copyright 1999, Simon Marlow and Andy Gill.  All rights
	reserved. </para>

	<para> Redistribution and use in source and binary forms, with
	or without modification, are permitted provided that the
	following conditions are met: </para>

	<itemizedlist>
	  <listitem>
	    <para>Redistributions of source code must retain the above
            copyright notice, this list of conditions and the
            following disclaimer.</para>
	  </listitem>
 
	  <listitem>
	    <para> Redistributions in binary form must reproduce the
            above copyright notice, this list of conditions and the
            following disclaimer in the documentation and/or other
            materials provided with the distribution.</para>
	  </listitem>
	</itemizedlist>

	<para>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS "AS
        IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
        LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
        FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
        SHALL THE COPYRIGHT HOLDERS BE LIABLE FOR ANY DIRECT,
        INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
        SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
        OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
        LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
        (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF
        THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
        OF SUCH DAMAGE.</para>
      </blockquote>
    </sect1>

    <sect1 id="sec-obtaining">
      <title>Obtaining <application/Happy/</title>

      <para> <application/Happy/'s web page can be found at <ulink
      url="http://www.haskell.org/happy/">http://www.haskell.org/happy/</ulink>.
      <application/Happy/ source and binaries can be downloaded from
      there.  There are several mirrors of this site, but since they
      tend to move around a bit I won't mention them here. </para>
      
    </sect1>

  </chapter>

<!-- Using Happy------------------------------------------------------------ -->

  <chapter id="sec-using">
    <title>Using <application/Happy/</title>

  <para> Users of <application/Yacc/ will find <application/Happy/
  quite familiar.  The basic idea is as follows: </para>

  <itemizedlist>
    <listitem>
      <para>Define the grammar you want to parse in a
      <application/Happy/ grammar file. </para>
    </listitem>

    <listitem>
      <para> Run the grammar through <application/Happy/, to generate
      a compilable Haskell module.</para>
    </listitem>

    <listitem>
      <para> Use this module as part of your Haskell program, usually
      in conjunction with a lexical analyser (a function that splits
      the input into ``tokens'', the basic unit of parsing).</para>
    </listitem>
  </itemizedlist>

  <para> Let's run through an example.  We'll implement a parser for a
  simple expression syntax, consisting of integers, variables, the
  operators <literal/+/, <literal/-/, <literal/*/,
  <literal>/</literal>, and the form <literal/let var = exp in exp/.
  The grammar file starts off like this:</para>

    <programlisting>
{
module Main where
}
</programlisting>

    <para>At the top of the file is an optional <firstterm>module
    header</firstterm>,
      <indexterm>
	<primary>module</primary>
	<secondary>header</secondary>
      </indexterm>
    which is just a Haskell module header enclosed in braces.  This
    code is emitted verbatim into the generated module, so you can put
    any Haskell code here at all.  In a grammar file, Haskell code is
    always contained between curly braces to distinguish it from the
    grammar.</para>

    <para>In this case, the parser will be a standalone program so
    we'll call the module <literal/Main/.</para>

    <para>Next comes a couple of declarations:</para>

<programlisting>
%name calc
%tokentype { Token }
</programlisting>

    <indexterm>
      <primary><literal/%name/</primary>
    </indexterm>
    <indexterm>
      <primary><literal/%tokentype/</primary>
    </indexterm>

    <para>The first line declares the name of the parsing function
    that <application/Happy/ will generate, in this case
    <literal/calc/.  In many cases, this is the only symbol you need
    to export from the module.</para>

    <para>The second line declares the type of tokens that the parser
    will accept.  The parser (i.e. the function <function/calc/) will
    be of type <literal/[Token] -> T/, where <literal/T/ is the return
    type of the parser, determined by the production rules
    below.</para>

    <para>Now we declare all the possible tokens:</para>

<programlisting>
%token 
      let             { TokenLet }
      in              { TokenIn }
      int             { TokenInt $$ }
      var             { TokenVar $$ }
      '='             { TokenEq }
      '+'             { TokenPlus }
      '-'             { TokenMinus }
      '*'             { TokenTimes }
      '/'             { TokenDiv }
      '('             { TokenOB }
      ')'             { TokenCB }
</programlisting>

    <indexterm>
      <primary><literal/%token/</primary>
    </indexterm>

    <para>The symbols on the left are the tokens as they will be
    referred to in the rest of the grammar, and to the right of each
    token enclosed in braces is a Haskell pattern that matches the
    token.  The parser will expect to receive a stream of tokens, each
    of which will match one of the given patterns (the definition of
    the <literal/Token/ datatype is given later).</para>

    <para>The <literal/&dollar;&dollar;/ symbol is a placeholder that
    represents the <emphasis/value/ of this token.  Normally the value
    of a token is the token itself, but by using the
    <literal/&dollar;&dollar;/ symbol you can specify some component
    of the token object to be the value. </para>

    <indexterm>
      <primary><literal/&dollar;&dollar;/</primary>
    </indexterm>

    <para>Like yacc, we include <literal/%%/ here, for no real
    reason.</para>

<programlisting>
%%
</programlisting>

    <para>Now we have the production rules for the grammar.</para>

<programlisting>
Exp   : let var '=' Exp in Exp  { Let $2 $4 $6 }
      | Exp1                    { Exp1 $1 }

Exp1  : Exp1 '+' Term           { Plus $1 $3 }
      | Exp1 '-' Term           { Minus $1 $3 }
      | Term                    { Term $1 }

Term  : Term '*' Factor         { Times $1 $3 }
      | Term '/' Factor         { Div $1 $3 }
      | Factor                  { Factor $1 }

Factor			  
      : int                     { Int $1 }
      | var                     { Var $1 }
      | '(' Exp ')'             { Brack $2 }
</programlisting>

    <indexterm>
      <primary>non-terminal</primary>
    </indexterm>
    <para>Each production consists of a <firstterm>non-terminal</>
    symbol on the left, followed by a colon, followed by one or more
    expansions on the right, separated by <literal/|/.  Each expansion
    has some Haskell code associated with it, enclosed in braces as
    usual.</para>

    <para>The way to think about a parser is with each symbol having a
    `value': we defined the values of the tokens above, and the
    grammar defines the values of non-terminal symbols in terms of
    sequences of other symbols (either tokens or non-terminals).  In a
    production like this:</para>

<programlisting>
n   : t_1 ... t_n   { E }
</programlisting>

    <para>whenever the parser finds the symbols <literal/t_1..t_n/ in
    the token stream, it constructs the symbol <literal/n/ and gives
    it the value <literal/E/, which may refer to the values of
    <literal/t_1...t_n/ using the symbols
    <literal/&dollar;1...&dollar;n/.</para>

    <para>The parser reduces the input using the rules in the grammar
    until just one symbol remains: the first symbol defined in the
    grammar (namely <literal/Exp/ in our example).  The value of this
    symbol is the return value from the parser.</para>

    <para>To complete the program, we need some extra code.  The
    grammar file may optionally contain a final code section, enclosed
    in curly braces.</para>

<programlisting>
{
</programlisting>

    <indexterm>
      <primary><function>happyError</></primary>
    </indexterm>
    <para>All parsers must declare the function <function/happyError/,
    which is called when an error is detected. </para>

<programlisting>
happyError :: [Token] -> a
happyError _ = error "Parse error"
</programlisting>

    <para><function/happyError/ doesn't have to call <function/error/:
    it can return a real value, which must be the same type as the
    return value of the parser itself.  A convenient way to deal with
    errors is to use an exception monad, which we'll talk about in
    <xref linkend="sec-monads">.  It's also possible to keep track of
    line numbers in the parser for use in error messages, this is
    described in <xref linkend="sec-line-numbers">.</para>

    <para>Next we can declare the data type that represents the parsed
    expression:</para>

<programlisting>
data Exp  
      = Let String Exp Exp
      | Exp1 Exp1

data Exp1 
      = Plus Exp1 Term 
      | Minus Exp1 Term 
      | Term Term

data Term 
      = Times Term Factor 
      | Div Term Factor 
      | Factor Factor

data Factor 
      = Int Int 
      | Var String 
      | Brack Exp
</programlisting>

    <para>And the data structure for the tokens...</para>

<programlisting>
data Token
      = TokenLet
      | TokenIn
      | TokenInt Int
      | TokenVar String
      | TokenEq
      | TokenPlus
      | TokenMinus
      | TokenTimes
      | TokenDiv
      | TokenOB
      | TokenCB
 deriving Show
</programlisting>

    <para>... and a simple lexer that returns this data
    structure.</para>

<programlisting>
lexer :: String -> [Token]
lexer [] = []
lexer (c:cs) 
      | isSpace c = lexer cs
      | isAlpha c = lexVar (c:cs)
      | isDigit c = lexNum (c:cs)
lexer ('=':cs) = TokenEq : lexer cs
lexer ('+':cs) = TokenPlus : lexer cs
lexer ('-':cs) = TokenMinus : lexer cs
lexer ('*':cs) = TokenTimes : lexer cs
lexer ('/':cs) = TokenDiv : lexer cs
lexer ('(':cs) = TokenOB : lexer cs
lexer (')':cs) = TokenCB : lexer cs

lexNum cs = TokenInt (read num) : lexer rest
      where (num,rest) = span isDigit cs

lexVar cs =
   case span isAlpha cs of
      ("let",rest) -> TokenLet : lexer rest
      ("in",rest)  -> TokenIn : lexer rest
      (var,rest)   -> TokenVar var : lexer rest
</programlisting>

    <para>And finally a top-level function to take some input, parse
    it, and print out the result.</para>

<programlisting>
main = getContents >>= print . calc . lexer
}
</programlisting>

    <para>And that's it! A whole lexer, parser and grammar in a few
    dozen lines.  Another good example is <application/Happy/'s own
    parser. Several features in <application/Happy/ were developed
    using this as an example.</para>

    <indexterm>
      <primary>info file</primary>
    </indexterm>

    <para>To generate the Haskell module for this parser, type the
    command <command/happy example.ly/ (where <filename/example.ly/ is
    the name of the grammar file).  The Haskell module will be placed
    in a file named <filename/example.hs/.  Additionally, invoking the
    command <command/happy example.ly -i/ will produce the file
    <filename/example.info/ which contains detailed information about
    the parser, including states and reduction rules (see <xref
    linkend="sec-info-files">).  This can be invaluable for debugging
    parsers, but requires some knowledge of the operation of a
    shift-reduce parser. </para>

    <sect1 id="sec-other-datatypes">
      <title>Returning other datatypes</title>

      <para>In the above example, we used a data type to represent the
      syntax being parsed.  However, there's no reason why it has to
      be this way: you could calculate the value of the expression on
      the fly, using productions like this:</para>

<programlisting>
Term  : Term '*' Factor         { $1 * $3 }
      | Term '/' Factor         { $1 / $3 }
      | Factor                  { $1 }
</programlisting>

      <para>The value of a <literal/Term/ would be the value of the
      expression itself, and the parser could return an integer.  </para>

      <para>This works for simple expression types, but our grammar
      includes variables and the <literal/let/ syntax.  How do we know
      the value of a variable while we're parsing it?  We don't, but
      since the Haskell code for a production can be anything at all,
      we could make it a function that takes an environment of
      variable values, and returns the computed value of the
      expression:</para>

<programlisting>
Exp   : let var '=' Exp in Exp  { \p -> $6 (($2,$4 p):p) }
      | Exp1                    { $1 }

Exp1  : Exp1 '+' Term           { \p -> $1 p + $3 p }
      | Exp1 '-' Term           { \p -> $1 p - $3 p }
      | Term                    { $1 }

Term  : Term '*' Factor         { \p -> $1 p * $3 p }
      | Term '/' Factor         { \p -> $1 p `div` $3 p }
      | Factor                  { $1 }

Factor			  
      : int                     { \p -> $1 }
      | var                     { \p -> case lookup $1 p of
	                                    Nothing -> error "no var"
					    Just i  -> i }
      | '(' Exp ')'             { $2 }
</programlisting>

      <para>The value of each production is a function from an
      environment <emphasis/p/ to a value.  When parsing a
      <literal/let/ construct, we extend the environment with the new
      binding to find the value of the body, and the rule for
      <literal/var/ looks up its value in the environment.  There's
      something you can't do in <literal/yacc/ :-)</para>

    </sect1>

    <sect1 id="sec-sequences"> 
      <title>Parsing sequences</title>

      <para>A common feature in grammars is a <emphasis/sequence/ of a
      particular syntactic element.  In EBNF, we'd write something
      like <literal/n+/ to represent a sequence of one or more
      <literal/n/s, and <literal/n*/ for zero or more.
      <application/Happy/ doesn't support this syntax explicitly, but
      you can define the equivalent sequences using simple
      productions.</para>

      <para>For example, the grammar for <application/Happy/ itself
      contains a rule like this:</para>

<programlisting>
prods : prod                   { [$1] }
      | prods prod             { $2 : $1 }
</programlisting>

      <para>In other words, a sequence of productions is either a
      single production, or a sequence of productions followed by a
      single production.  This recursive rule defines a sequence of
      one or more productions.</para>

      <para>One thing to note about this rule is that we used
      <emphasis/left recursion/ to define it - we could have written
      it like this:</para>

      <indexterm>
	<primary>recursion, left vs. right</primary>
      </indexterm>

<programlisting>
prods : prod                  { [$1] }
      | prod prods            { $1 : $2 }
</programlisting>

      <para>The only reason we used left recursion is that
      <application/Happy/ is more efficient at parsing left-recursive
      rules; they result in a constant stack-space parser, whereas
      right-recursive rules require stack space proportional to the
      length of the list being parsed.  This can be extremely
      important where long sequences are involved, for instance in
      automatically generated output.  For example, the parser in GHC
      used to use right-recursion to parse lists, and as a result it
      failed to parse some <application/Happy/-generated modules due
      to running out of stack space!</para>

      <para>One implication of using left recursion is that the resulting
      list comes out reversed, and you have to reverse it again to get
      it in the original order.  Take a look at the
      <application/Happy/ grammar for Haskell for many examples of
      this.</para>

      <para>Parsing sequences of zero or more elements requires a
      trivial change to the above pattern:</para>

<programlisting>
prods : {- empty -}           { [] }
      | prods prod            { $2 : $1 }
</programlisting>

      <para>Yes - empty productions are allowed.  The normal
      convention is to include the comment <literal/{- empty -}/ to
      make it more obvious to a reader of the code what's going
      on.</para>

      <sect2 id="sec-separators">
	<title>Sequences with separators</title>

	<para>A common type of sequence is one with a
        <emphasis/separator/: for instance function bodies in C
        consist of statements separated by semicolons.  To parse this
        kind of sequence we use a production like this:</para>

<programlisting>
stmts : stmt                   { [$1] }
      | stmts ';' stmt         { $3 : $1 }
</programlisting>

	<para>If the <literal/;/ is to be a <emphasis/terminator/
        rather than a separator (i.e. there should be one following
        each statement), we can remove the semicolon from the above
        rule and redefine <literal/stmt/ as</para>

<programlisting>
stmt : stmt1 ';'              { $1 }
</programlisting>

	<para>where <literal/stmt1/ is the real definition of statements.</para>

        <para>We might like to allow extra semicolons between
        statements, to be a bit more liberal in what we allow as legal
        syntax.  We probably just want the parser to ignore these
        extra semicolons, and not generate a ``null statement'' value
        or something.  The following rule parses a sequence or zero or
        more statements separated by semicolons, in which the
        statements may be empty:</para>

<programlisting>
stmts : stmts ';' stmt          { $3 : $1 }
      | stmts ';'               { $1 }
      | stmt			{ [$1] }
      | {- empty -}		{ [] }
</programlisting>

	<para>Parsing sequences of <emphasis/one/ or more possibly
	null statements is left as an exercise for the reader...</para>

    </sect2>
    </sect1>
    
    <sect1 id="sec-ambiguities">
      <title>Ambiguities</title>

      <para>(section under construction)</para>

    </sect1>
    
    <sect1 id="sec-type-signatures">
      <title>Type Signatures</title>

      <indexterm>
	<primary>type</primary>
	<secondary>signatures in grammar</secondary>
      </indexterm>

      <para><application/Happy/ allows you to include type signatures
      in the grammar file itself, to indicate the type of each
      production.  This has several benefits:</para>

      <itemizedlist>
	<listitem>
	  <para> Documentation: including types in the grammar helps
          to document the grammar for someone else (and indeed
          yourself) reading the code.</para>
	</listitem>

	<listitem>
	  <para> Fixing type errors in the generated module can become
          slightly easier if <application/Happy/ has inserted type
          signatures for you.  This is a slightly dubious benefit,
          since type errors in the generated module are still somewhat
          difficult to find.  </para>
	</listitem>

	<listitem>
	  <para> Type signatures generally help the Haskell compiler
          to compile the parser faster.  This is important when really
          large grammar files are being used.</para>
	</listitem>
      </itemizedlist>

      <para>The syntax for type signatures in the grammar file is as
      follows:</para>

<programlisting>
stmts   :: { [ Stmt ] }
stmts   : stmts stmt                { $2 : $1 }
	| stmt                      { [$1] }
</programlisting>

      <para>In fact, you can leave out the superfluous occurrence of
      <literal/stmts/:</para>

<programlisting>
stmts   :: { [ Stmt ] }
	: stmts stmt                { $2 : $1 }
	| stmt                      { [$1] }
</programlisting>

      <para>Note that currently, you have to include type signatures
      for <emphasis/all/ the productions in the grammar to benefit
      from the second and third points above.  This is due to boring
      technical reasons, but it is hoped that this restriction can be
      removed in the future.</para>

    </sect1>
    
    <sect1 id="sec-monads">
      <title>Monadic Parsers</title>

      <indexterm>
	<primary>monadic</primary>
	<secondary>parsers</secondary>
      </indexterm>

      <para><application/Happy/ has support for threading a monad
      through the generated parser.  This might be useful for several
      reasons:</para>

      <itemizedlist>

	<listitem>
	  <indexterm>
	    <primary>parse errors</primary>
	    <secondary>handling</secondary>
	  </indexterm>
<!--	  <indexterm>
	    <primary>error</primary>
	    <secondary>parse</secondary>
	    <see>parse errors</see>
	  </indexterm> 
-->
	  <para> Handling parse errors by using an exception monad
          (see <xref linkend="sec-exception">).</para>
	</listitem>

	<listitem>
	  <indexterm>
	    <primary>line numbers</primary>
	  </indexterm>
	  <para> Keeping track of line numbers in the input file, for
          example for use in error messages (see <xref
          linkend="sec-line-numbers">).</para>
	</listitem>

	<listitem>
	  <para> Performing IO operations during parsing.</para>
	</listitem>

	<listitem>
	  <para> Parsing languages with context-dependencies (such as
          C) require some state in the parser.</para>
	</listitem>

</itemizedlist>

      <para>Adding monadic support to your parser couldn't be simpler.
      Just add the following directive to the declaration section of
      the grammar file:</para>

<programlisting>
%monad { &lt;type&gt; } [ { &lt;then&gt; } { &lt;return&gt; } ]
</programlisting>

      <indexterm>
	<primary><literal>%monad</></primary>
      </indexterm>

      <para>where <literal/&lt;type&gt;/ is the type constructor for
      the monad, <literal/&lt;then&gt;/ is the bind operation of the
      monad, and <literal/&lt;return&gt;/ is the return operation. If
      you leave out the names for the bind and return operations,
      <application/Happy/ assumes that <literal/&lt;type&gt;/ is an
      instance of the standard Haskell type class <literal/Monad/ and
      uses the overloaded names for the bind and return
      operations.</para>

      <para>When this declaration is included in the grammar,
      <application/Happy/ makes a couple of changes to the generated
      parser: the types of the main parser function and
      <literal/happyError/ become <literal/[Token] -&gt; P a/ where
      <literal/P/ is the monad type constructor, and <literal/a/ is
      the type of the top production.  In other words,
      <application/Happy/ adds an application of the
      <literal/&lt;return&gt;/ operation defined in the declaration
      above, around the result of the parser (<literal/happyError/ is
      affected because it must have the same return type as the
      parser).  And that's all it does.</para>

      <indexterm>
	<primary><function>happyError</></primary>
      </indexterm>
      <para>This still isn't very useful: all you can do is return
      something of monadic type from <literal/happyError/.  How do you
      specify that the productions can also have type <literal/P a/?
      Most of the time, you don't want a production to have this type:
      you'd have to write explicit <literal/returnP/s everywhere.
      However, there may be a few rules in a grammar that need to get
      at the monad, so <application/Happy/ has a special syntax for
      monadic actions:</para>

<programlisting>
n  :  t_1 ... t_n          {% &lt;expr&gt; }
</programlisting>

      <indexterm>
	<primary>monadic</primary>
	<secondary>actions</secondary>
      </indexterm>
      <para>The <literal/%/ in the action indicates that this is a
      monadic action, with type <literal/P a/, where <literal/a/ is
      the real return type of the production.  When
      <application/Happy/ reduces one of these rules, it evaluates the
      expression </para>

<programlisting>
&lt;expr&gt; `then` \result -> &lt;continue parsing&gt;
</programlisting>

      <para><application/Happy/ uses <literal/result/ as the real
      semantic value of the production.  During parsing, several
      monadic actions might be reduced, resulting in a sequence
      like</para>

<programlisting>
&lt;expr1&gt; `then` \r1 ->
&lt;expr2&gt; `then` \r2 ->
...
return &lt;expr3&gt;
</programlisting>

      <para>The monadic actions are performed in the order that they
      are <emphasis/reduced/.  If we consider the parse as a tree,
      then reductions happen in a depth-first left-to-right manner.
      The great thing about adding a monad to your parser is that it
      doesn't impose any performance overhead for normal reductions -
      only the monadic ones are translated like this.</para>

      <para>Take a look at the Haskell parser for a good illustration
      of how to use a monad in your parser: it contains examples of
      all the principles discussed in this section, namely parse
      errors, a threaded lexer, line/column numbers, and state
      communication between the parser and lexer.</para>

      <para>The following sections consider a couple of uses for
      monadic parsers, and describe how to also thread the monad
      through the lexical analyser.</para>

      <sect2 id="sec-exception">
	<title>Handling Parse Errors</title>
	<indexterm>
	  <primary>parse errors</primary>
	  <secondary>handling</secondary>
	</indexterm>
	    
      <para>It's not very convenient to just call <literal/error/ when
      a parse error is detected: in a robust setting, you'd like the
      program to recover gracefully and report a useful error message
      to the user.  Exceptions (of which errors are a special case)
      are normally implemented in Haskell by using an exception monad,
      something like:</para>

<programlisting>
data E a = Ok a | Failed String

thenE :: E a -> (a -> E b) -> E b
m `thenE` k = 
   case m of 
       Ok a -> k a
	 Failed e -> Failed e

returnE :: a -> E a
returnE a = Ok a

failE :: String -> E a
failE err = Failed err

catchE :: E a -> (String -> E a) -> E a
catchE m k = 
   case m of
      Ok a -> OK a
	Failed e -> k e
</programlisting>

	<para>This monad just uses a string as the error type.  The
        functions <literal/thenE/ and <literal/returnE/ are the usual
        bind and return operations of the monad, <literal/failE/
        raises an error, and <literal/catchE/ is a combinator for
        handling exceptions.</para>

	<para>We can add this monad to the parser with the declaration</para>

<programlisting>
%monad { E } { thenE } { returnE }
</programlisting>

	<para>Now, without changing the grammar, we can change the
        definition of <literal/happyError/ and have something sensible
        happen for a parse error:</para>

<programlisting>
happyError tokens = failE "Parse error"
</programlisting>
	  <indexterm>
	    <primary><function>happyError</></primary>
	  </indexterm>

	<para>The parser now raises an exception in the monad instead
	of bombing out on a parse error.</para>

	<para>We can also generate errors during parsing.  There are
        times when it is more convenient to parse a more general
        language than that which is actually intended, and check it
        later.  An example comes from Haskell, where the precedence
        values in infix declarations must be between 0 and 9:</para>

<programlisting>
prec :: { Int }
      : int    {% if $1 < 0 || $1 > 9 
	                then failE "Precedence out of range"
		        else returnE $1
		}
</programlisting>

	<para>The monadic action allows the check to be placed in the
	parser itself, where it belongs.</para>

    </sect2>
    
    <sect2 id="sec-lexers">
      <title>Threaded Lexers</title>
	<indexterm>
	  <primary>lexer, threaded</primary>
	</indexterm>
	<indexterm>
	  <primary>monadic</primary>
	  <secondary>lexer</secondary>
	</indexterm>

	<para><application/Happy/ allows the monad concept to be
	extended to the lexical analyser, too.  This has several
	useful consequences:</para>

	<itemizedlist>
	  <listitem>
	    <para> Lexical errors can be treated in the same way as
            parse errors, using an exception monad.</para>
	    <indexterm>
	      <primary>parse errors</primary>
	      <secondary>lexical</secondary>
	    </indexterm>
	  </listitem>
	  <listitem>
	    <para> Information such as the current file and line
            number can be communicated between the lexer and
            parser. </para>
	  </listitem>
	  <listitem>
	    <para> General state communication between the parser and
            lexer - for example, implementation of the Haskell layout
            rule requires this kind of interaction.
            </para>
	  </listitem>
	  <listitem>
	    <para> IO operations can be performed in the lexer - this
            could be useful for following import/include declarations
            for instance.</para>
	  </listitem>
	</itemizedlist>

	<para>A monadic lexer is requested by adding the following
	declaration to the grammar file:</para>

<programlisting>
%lexer { &lt;lexer&gt; } { &lt;eof&gt; }
</programlisting>
	
	<indexterm>
	  <primary><literal>%lexer</></primary>
	</indexterm>

	<para>where <literal/&lt;lexer&gt;/ is the name of the lexical
        analyser function, and <literal/&lt;eof&gt;/ is a token that
        is to be treated as the end of file.</para>

	<para>When using a monadic lexer, the parser no longer reads a
        list of tokens.  Instead, it calls the lexical analysis
        function for each new token to be read.  This has the side
        effect of eliminating the intermediate list of tokens, which
        is a slight performance win.</para>

	<para>The type of the main parser function and
        <literal/happyError/ is now just <literal/P a/ - the input is
        being handled completely within the monad.</para>
	<indexterm>
	  <primary><function>happyError</></primary>
	</indexterm>

	<para>The lexical analysis function must have the following
	type:</para>

<programlisting>
lexer :: (Token -> P a) -> P a
</programlisting>

	<para>where <literal/P/ is the monad type constructor declared
        with <literal/%monad/, and <literal/a/ can be replaced by the
        parser return type if desired.</para>

	<para>You can see from this type that the lexer takes a
        <emphasis/continuation/ as an argument.  The lexer is to find
        the next token, and pass it to this continuation to carry on
        with the parse.  Obviously, we need to keep track of the input
        in the monad somehow, so that the lexer can do something
        different each time it's called!</para>

	<para>Let's take the exception monad above, and extend it to
        add the input string so that we can use it with a threaded
        lexer.</para>

<programlisting>
data ParseResult a = Ok a | Failed String
type P a = String -> ParseResult a

thenP :: P a -> (a -> P b) -> P b
m `thenP` k = \s ->
   case m s of 
       Ok a -> k a s
	 Failed e -> Failed e

returnP :: a -> P a
returnP a = \s -> Ok a

failP :: String -> P a
failP err = \s -> Failed err

catchP :: P a -> (String -> P a) -> P a
catchP m k = \s ->
   case m s of
      Ok a -> OK a
	Failed e -> k e s
</programlisting>

	<para>Notice that this isn't a real state monad - the input
        string just gets passed around, not returned.  Our lexer will
        now look something like this:</para>

<programlisting>
lexer :: (Token -> P a) -> P a
lexer cont s = 
    ... lexical analysis code ...
    cont token s'
</programlisting>

	<para>the lexer grabs the continuation and the input string,
        finds the next token <literal/token/, and passes it together
        with the remaining input string <literal/s'/ to the
        continuation.</para>

	<para>We can now indicate lexical errors by ignoring the
        continuation and calling <literal/failP "error message" s/
        within the lexer (don't forget to pass the input string to
        make the types work out).</para>

	<para>This may all seem a bit weird.  Why, you ask, doesn't
        the lexer just have type <literal/P Token/?  Well, the
        decision was taken to use a continuation purely for
        performance reasons.  If the lexer must return a token, then
        it turns out that the input string must be a real state
        object, and the monad has to return it as well as pass it
        around.  If you want a lexer of type <literal/P Token/, then
        just define a wrapper to deal with the continuation:</para>

<programlisting>
lexwrap :: (Token -> P a) -> P a
lexwrap cont = real_lexer `thenP` \token -> cont token
</programlisting>

    </sect2>

    <sect2 id="sec-line-numbers">
      <title>Line Numbers</title>

	<indexterm>
	  <primary>line numbers</primary>
	</indexterm>

	<indexterm>
	  <primary><literal>%newline</></primary>
	</indexterm>
	<para>Previous versions of <application/Happy/ had a
        <literal/%newline/ directive that enabled simple line numbers
        to be counted by the parser and referenced in the actions.  We
        warned you that this facility may go away and be replaced by
        something more general, well guess what? :-)</para>

	<para>Line numbers can now be dealt with quite
        straightforwardly using a monadic parser/lexer combination.
        Ok, we have to extend the monad a bit more:</para>

<programlisting>
type LineNumber = Int
type P a = String -> LineNumber -> ParseResult a

getLineNo :: P LineNumber
getLineNo = \s l -> Ok l
</programlisting>

	<para>(the rest of the functions in the monad follow by just
        adding the extra line number argument in the same way as the
        input string).  Again, the line number is just passed down,
        not returned: this is OK because of the continuation-based
        lexer that can change the line number and pass the new one to
        the continuation.</para>

	<para>The lexer can now update the line number as follows:</para>

<programlisting>
lexer cont s =
  case s of
     '\n':s  ->  \line -> lexer cont s (line + 1)
     ... rest of lexical analysis ...
</programlisting>

	<para>It's as simple as that.  Take a look at
        <application/Happy/'s own parser if you have the sources lying
        around, it uses a monad just like the one above.</para>

        <para>Reporting the line number of a parse error is achieved
        by changing <literal/happyError/ to look something like
        this:</para>

<programlisting>
happyError :: P a
happyError = getLineNo `thenP` \line -> 
             failP (show line ++ ": parse error")
</programlisting>
	<indexterm>
	  <primary><function>happyError</></primary>
	</indexterm>

	<para>We can also get hold of the line number during parsing,
        to put it in the parsed data structure for future reference.
        A good way to do this is to have a production in the grammar
        that returns the current line number: </para>

<programlisting>
lineno :: { LineNumber }
        : {- empty -}      {% getLineNo }
</programlisting>

	<para>The semantic value of <literal/lineno/ is the line
        number of the last token read - this will always be the token
        directly following the <literal/lineno/ symbol in the grammar,
        since <application/Happy/ always keeps one lookahead token in
        reserve.</para>

      </sect2>

      <sect2 id="sec-monad-summary">
	<title>Summary</title>

	<para>The types of various functions related to the parser are
        dependent on what combination of <literal/%monad/ and
        <literal/%lexer/ directives are present in the grammar.  For
        reference, we list those types here.</para>

	<indexterm>
	  <primary>type</primary>
	  <secondary>of <function>happyError</></secondary>
	</indexterm>
	<indexterm>
	  <primary>type</primary>
	  <secondary>of parser</secondary>
	</indexterm>
	<indexterm>
	  <primary>type</primary>
	  <secondary>of lexer</secondary>
	</indexterm>

	<itemizedlist>
	  <listitem>
	    <formalpara>
	      <title> No <literal/&percnt;monad/ or
	      <literal/&percnt;lexer/ </title>
	      <para>
<programlisting>
parse      :: [Token] -> a
happyError :: [Token] -> a
</programlisting>
</para>
	    </formalpara>
	  </listitem>

	  <listitem>
	    <formalpara>
	      <title> with <literal/%monad/ </title>
	      <para>
<programlisting>
parse      :: [Token] -> P a
happyError :: [Token] -> P a
</programlisting>
</para>
	    </formalpara>
	  </listitem>


	  <listitem>
	    <formalpara>
	      <title> with <literal/%lexer/ </title>
	      <para><programlisting>
parse      :: T a
happyError :: T a
lexer      :: (Token -> T a) -> T a
</programlisting>
where the type constructor <literal/T/ is whatever you want (usually <literal/T
a = String -> a/.  I'm not sure if this is useful, or even if it works
properly.</para>
	    </formalpara>
	  </listitem>

	  <listitem>
	    <formalpara>
	      <title> with <literal/%monad/ and <literal/%lexer/ </title>
	      <para><programlisting>
parse      :: P a
happyError :: P a
lexer      :: (Token -> P a) -> P a
</programlisting>
</para>
	    </formalpara>
	  </listitem>
	</itemizedlist>
      
      </sect2>
    </sect1>

    <sect1 id="sec-error">
      <title>The Error Token</title>
      <indexterm>
	<primary>error token</primary>
      </indexterm>

      <para><application/Happy/ supports a limited form of error
      recovery, using the special symbol <literal/error/ in a grammar
      file.  When <application/Happy/ finds a parse error during
      parsing, it automatically inserts the <literal/error/ symbol; if
      your grammar deals with <literal/error/ explicitly, then it can
      detect the error and carry on.</para>

      <para>For example, the <application/Happy/ grammar for Haskell
      uses error recovery to implement Haskell layout.  The grammar
      has a rule that looks like this:</para>

<programlisting>
close : '}'                  { () }
      | error		     { () }
</programlisting>

      <para>This says that a close brace in a layout-indented context
      may be either a curly brace (inserted by the lexical analyser),
      or a parse error.  </para>

      <para>This rule is used to parse expressions like <literal/let x
      = e in e'/: the layout system inserts an open brace before
      <literal/x/, and the occurrence of the <literal/in/ symbol
      generates a parse error, which is interpreted as a close brace
      by the above rule.</para>

      <indexterm>
	<primary><application/yacc/</primary>
      </indexterm>
      <para>Note for <literal/yacc/ users: this form of error recovery
      is strictly more limited than that provided by <literal/yacc/.
      During a parse error condition, <literal/yacc/ attempts to
      discard states and tokens in order to get back into a state
      where parsing may continue; <application/Happy/ doesn't do this.
      The reason is that normal <literal/yacc/ error recovery is
      notoriously hard to describe, and the semantics depend heavily
      on the workings of a shift-reduce parser.  Furthermore,
      different implementations of <literal/yacc/ appear to implement
      error recovery differently.  <application/Happy/'s limited error
      recovery on the other hand is well-defined, as is just
      sufficient to implement the Haskell layout rule (which is why it
      was added in the first place).</para>

    </sect1>
  </chapter>

<!-- Invoking ------------------------------------------------------------ -->

  <chapter id="sec-invoking">
    <title>Invoking <application/Happy/</title>

    <para>An invocation of <application/Happy/ has the following syntax:</para>

<programlisting>
happy [ options ] &lt;filename&gt; [ options ]
</programlisting>

    <para>All the command line options are optional (!) and may occur
    either before or after the input file name.</para>

    <para>There are two types of grammar files, <filename/file.y/ and
    <filename/file.ly/, with the latter observing the reverse comment
    bird track convention (i.e. each code line must begin with '>').
    The examples distributed with <application/Happy/ are all of the .ly
    form.</para>
    <indexterm>
      <primary>literate grammar files</primary>
    </indexterm>

    <para>Caveat: When using hbc (Chalmers Haskell) the command
    argument structure is slightly different. This is because the hbc
    run time system takes some flags as its own (for setting things
    like the heap size, etc).  This problem can be circumvented by
    adding a single <literal/-/ to your command line.  So when using a
    hbc generated version of <application/Happy/, the argument
    structure is:</para>

<programlisting>
happy - [ options ] &lt;filename&gt; [ options ]
</programlisting>

    <para>Pedantic programmers can either use aliases or a short shell
    wrapper to automatically add the <literal/-/, along with any
    required run time system arguments (Or just use GHC to compile
    <application/Happy/!).</para>

    <para>The flags accepted by <application/Happy/ are as follows:</para>

    <variablelist>

      <varlistentry>
	<term> <literal/-a | --arrays/ </term> 
	<listitem>
	  <indexterm>
	    <primary>arrays</primary>
	  </indexterm>
	  <indexterm>
	    <primary>back-ends</primary>
	    <secondary>arrays</secondary>
	  </indexterm>
	  <para> Instructs <application/Happy/ to generate a parser
          using an array-based shift reduce parser.  Currently this
          generates slower parsers for two reasons: standard Haskell
          arrays are surrounded by overloading and bounds-checking
          which makes lookup quite expensive, and secondly current
          compilers don't know how to generate static objects
          (i.e. they generate the code which builds the array at
          run-time).</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-g | --ghc/ </term>
	<listitem>
	  <indexterm>
	    <primary>ghc</primary>
	  </indexterm>
	  <indexterm>
	    <primary>back-ends</primary>
	    <secondary>ghc</secondary>
	  </indexterm>
	  <para> Instructs <application/Happy/ to generate a parser
	  that uses ghc-specific extensions to obtain faster code.
	  When compiling the resulting Haskell module, remember to add
	  the declaration <literal/import GlaExts/ to the module
	  header.</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-c | --coerce/ </term>
	<listitem>
	  <indexterm>
	    <primary>coerce</primary>
	  </indexterm>
	  <indexterm>
	    <primary>back-ends</primary>
	    <secondary>coerce</secondary>
	  </indexterm>
	  <para> Use GHC's <literal/unsafeCoerce#/ extension to
          generate smaller faster parsers.  One drawback is that some
          type safety is lost, which means that a parser generated
          with <literal/-c/ may compile fine but crash at run-time.
          Be sure to compile your grammar without <literal/-c/ first
          to ensure it is type-correct.</para>

	  <para>This option quite a significant effect on the
          performance of the resulting parser, but remember that
          parsers generated this way can only be compiled by GHC 3.02
          and above.  This option may only be used in conjuction with
          <literal/-g/.</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-i[&lt;filename&gt;] |
	--info[=&lt;filename&gt;]/ </term>
	<listitem>
	  <indexterm>
	    <primary>info file</primary>
	  </indexterm>
	  <para> Directs <application/Happy/ to produce an info file containing
          detailed information about the grammar, parser states,
          parser actions, and conflicts.  Info files are vital during
          the debugging of grammars.  The filename argument is
          optional, and if omitted the info file will be written to
          <literal/&lt;file&gt;.info/ (where <literal/&lt;file&gt/; is
          the input file name with any extension removed). </para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-o &lt;filename&gt; |
	--outfile=&lt;filename&gt;/ </term>
	<listitem>
	  <para>Specifies the destination of the generated parser
          module.  If omitted, the parser will be placed in
          <literal/&lt;file&gt;.hs/, where <literal/&lt;file&gt;/ is
          the name of the input file with any extension
          removed.</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-m &lt;name&gt; | --magic-name=&lt;name&gt;/ </term>
	<listitem>
	  <para> <application/Happy/ prefixes all the symbols it uses internally
          with either <literal/happy/ or <literal/Happy/.  To use a
          different string, for example if the use of <literal/happy/
          is conflicting with one of your own functions, specify the
          prefix using the <literal/-m/ option.</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-v | --version/ </term>
	<listitem>
	  <para>Print version information on standard output then exit successfully.</para>
	</listitem>
      </varlistentry>

      <varlistentry>
	<term> <literal/-t &lt;directory&gt; | --template
&lt;directory&gt;/ </term> 
	<listitem>
	  <indexterm>
	    <primary>template files</primary>
	  </indexterm>
	  <para>Instructs <application/Happy/ to use this directory
          when looking for template files: these files contain the
          static code that <application/Happy/ includes in every
          generated parser.  You shouldn't need to use this option if
          <application/Happy/ is properly configured for your
          computer.</para>
	</listitem>
      </varlistentry>
      
    </variablelist>

    <para>Note: only one of the options <literal/-g/ and <literal/-a/
    may be given (or their long versions).  There is no array-based
    parser with ghc extensions yet, but this is planned for a future
    version.</para>
    
  </chapter>

  <chapter id="sec-grammar-files">
    <title>Syntax of Grammar Files</title>
    
    <para>The input to <application/Happy/ is a text file containing
    the grammar of the language you want to parse, together with some
    annotations that help the parser generator make a legal Haskell
    module that can be included in your program.  This section gives
    the exact syntax of grammar files. </para>

    <para>The overall format of the grammar file is given below:</para>

<programlisting>
&lt;optional module header&gt;
&lt;directives&gt;
%%
&lt;grammar&gt;
&lt;optional module trailer&gt;
</programlisting>

    <indexterm>
      <primary>module</primary>
      <secondary>header</secondary>
    </indexterm>
    <indexterm>
      <primary>module</primary>
      <secondary>trailer</secondary>
    </indexterm>
    <para>If the name of the grammar file ends in <literal/.ly/, then
    it is assumed to be a literate script.  All lines except those
    beginning with a <literal/&gt/ will be ignored, and the
    <literal/&gt/ will be stripped from the beginning of all the code
    lines.  There must be a blank line between each code section
    (lines beginning with <literal/&gt/) and comment section.
    Grammars not using the literate notation must be in a file with
    the <literal/.y/ suffix.</para>
    
    <sect1 id="sec-lexical-rules">
      <title>Lexical Rules</title>

<para>Identifiers in <application/Happy/ grammar files must take the following form (using
the BNF syntax from the Haskell Report):</para>

<programlisting>
        id      ::= alpha { idchar }
                  | ' { any{^'} | \' } '
                  | " { any{^"} | \" } "

        alpha   ::= A | B | ... | Z
                  | a | b | ... | z

        idchar  ::= alpha
                  | 0 | 1 | ... | 9
                  | _
</programlisting>

    </sect1>

    <sect1 id="sec-module-header">
      <title>Module Header</title>

      <indexterm>
	<primary>module</primary>
	<secondary>header</secondary>
      </indexterm>
      <para>This section is optional, but if included takes the
      following form:</para>

<programlisting>
{  
&lt;Haskell module header&gt;
}
</programlisting>

      <para>The Haskell module header contains the module name,
      exports, and imports.  No other code is allowed in the
      header---this is because <application/Happy/ may need to include
      its own <literal/import/ statements directly after the user
      defined header.</para>

    </sect1>

    <sect1 id="sec-directives">
      <title>Directives</title>

      <para>This section contains a number of lines of the form:</para>

<programlisting>
%&lt;directive name&gt; &lt;argument&gt; ...
</programlisting>

      <para>The statements here are all annotations to help
      <application/Happy/ generate the Haskell code for the grammar.
      Some of them are optional, and some of them are required.</para>

      <sect2 id="sec-token-type">
	<title>Token Type</title>

<programlisting>
%tokentype   { &lt;valid Haskell type&gt; }
</programlisting>

	<indexterm>
	  <primary><literal>%tokentype</></primary>
	</indexterm>
	<para>(mandatory) The <literal/%tokentype/ directive gives the
        type of the tokens passed from the lexical analyser to the
        parser (in order that <application/Happy/ can supply types for
        functions and data in the generated parser).</para>

      </sect2>

      <sect2 id="sec-tokens">
	<title>Tokens</title>

<programlisting>
%token &lt;name&gt; { &lt;Haskell pattern&gt; }
       &lt;name&gt; { &lt;Haskell pattern&gt; }
       ...
</programlisting>

	<indexterm>
	  <primary><literal>%token</></primary>
	</indexterm>
	<para>(mandatory) The <literal/%token/ directive is used to
        tell <application/Happy/ about all the terminal symbols used
        in the grammar.  Each terminal has a name, by which it is
        referred to in the grammar itself, and a Haskell
        representation enclosed in braces.  Each of the patterns must
        be of the same type, given by the <literal/%tokentype/
        directive.</para>

	<para>The name of each terminal follows the lexical rules for
        <application/Happy/ identifiers given above.  There are no
        lexical differences between terminals and non-terminals in the
        grammar, so it is recommended that you stick to a convention;
        for example using upper case letters for terminals and lower
        case for non-terminals, or vice-versa.</para>

	<para><application/Happy/ will give you a warning if you try
        to use the same identifier both as a non-terminal and a
        terminal, or introduce an identifier which is declared as
        neither.</para>

	<para>To save writing lots of projection functions that map
        tokens to their components, you can include
        <literal/&dollar;&dollar;/ in your Haskell pattern. For
        example:</para>
	<indexterm>
	  <primary><literal>&dollar;&dollar;</></primary>
	</indexterm>

<programlisting>
%token INT { TokenInt $$ }
       ...
</programlisting>

<para>This makes the semantic value of <literal/INT/ refer to the first argument
of <literal/TokenInt/ rather than the whole token, eliminating the need for
any projection function.</para>

      </sect2>

      <sect2 id="sec-parser-name">
	<title>Parser Name</title>

<programlisting>
%name &lt;Haskell identifier&gt;
</programlisting>
	<indexterm>
	  <primary><literal>%name</></primary>
	</indexterm>

	<para>(optional) The <literal/%name/ directive is followed by
        a valid Haskell identifier, and gives the name of the
        top-level parsing function in the generated parser.  This is
        the only function that needs to be exported from a parser
        module.</para>

	<para>If the parser name directive is omitted, it defaults to
        <literal/happyParse/.</para>
	<indexterm>
	  <primary><function>happyParse</></primary>
	</indexterm>

      </sect2>

      <sect2 id="sec-monad-decl">
	<title>Monad Directive</title>

<programlisting>
%monad { &lt;type&gt; } { &lt;then&gt; } { &lt;return&gt; }
</programlisting>
	<indexterm>
	  <primary><literal>%monad</></primary>
	</indexterm>

	<para>(optional) The <literal/%monad/ directive takes three
        arguments: the type constructor of the monad, the
        <literal/then/ (or <literal/bind/) operation, and the
        <literal/return/ (or <literal/unit/) operation.  The type
        constructor can be any type with kind <literal/* -&gt; */.</para>

	<para>Monad declarations are described in more detail in <xref
        linkend="sec-monads">.</para>
	
      </sect2>

      <sect2 id="sec-lexer-decl">
	<title>Lexical Analyser</title>

<programlisting>
%lexer { &lt;lexer&gt; } { &lt;eof&gt; }
</programlisting>
	<indexterm>
	  <primary><literal>%lexer</></primary>
	</indexterm>

	<para>(optional) The <literal/%lexer/ directive takes two
        arguments: <literal/&lt;lexer&gt;/ is the name of the lexical
        analyser function, and <literal/&lt;eof&gt;/ is a token that
        is to be treated as the end of file.</para>

	<para>Lexer declarations are described in more detail in <xref
        linkend="sec-lexers">.</para>
	
      </sect2>
    </sect1>

    <sect1 id="sec-grammar">
      <title>Grammar</title>

      <para>The grammar section comes after the directives, separated
      from them by a double-percent (<literal/%%/) symbol.  This
      section contains a number of <emphasis/productions/, each of
      which defines a single non-terminal.  Each production has the
      following syntax:</para>
      <indexterm>
	<primary><literal>%%</></primary>
      </indexterm>

<programlisting>
&lt;non-terminal&gt; [ :: { &lt;type&gt; } ]
        :  &lt;id&gt; ... {[%] &lt;expression&gt; }
      [ |  &lt;id&gt; ... {[%] &lt;expression&gt; }
        ... ]
</programlisting>

      <para>The first line gives the non-terminal to be defined by the
      production and optionally its type (type signatures for
      productions are discussed in <xref
      linkend="sec-type-signatures">).</para>

      <para>Each production has at least one, and possibly many
      right-hand sides.  Each right-hand side consists of zero or more
      symbols (terminals or non-terminals) and a Haskell expression
      enclosed in braces.  The expression represents the semantic
      value of the non-terminal, and may refer to the semantic values
      of the symbols in the right-hand side using the meta-variables
      <literal/&dollar;1 ... &dollar;n/.</para>

      <para>Remember that all the expressions for a production must
      have the same type.</para>

      <para>A semantic value of the form <literal/{% ... }/ is a
      <emphasis/monadic action/, and is only valid when the grammar
      file contains a <literal/%monad/ directive (<xref
      linkend="sec-monad-decl">).  Monadic actions are discussed in
      <xref linkend="sec-monads">.</para>
      <indexterm>
	<primary>monadic</primary>
	<secondary>action</secondary>
      </indexterm>

      </sect1>

    <sect1 id="sec-module-trailer">
      <title>Module Trailer</title>
      <indexterm>
	<primary>module</primary>
	<secondary>trailer</secondary>
      </indexterm>

      <para>The module trailer is optional, comes right at the end of
      the grammar file, and takes the same form as the module
      header:</para>

<programlisting>
{
&lt;Haskell code&gt;
}
</programlisting>

      <para>This section is used for placing auxiliary definitions
      that need to be in the same module as the parser.  In small
      parsers, it often contains a hand-written lexical analyser too.
      There is no restriction on what can be placed in the module
      trailer, and any code in there is copied verbatim into the
      generated parser file.</para>

      </sect1>
    </chapter>
  
  <chapter id="sec-info-files">
    <title>Info Files</title>
    <indexterm>
      <primary>info files</primary>
    </indexterm>

    <para>(section under construction)</para>

  </chapter>
  
  <chapter id="sec-tips">
    <title>Tips</title>

    <para>This section contains a lot of accumulated lore about using
    <application/Happy/.</para>

    <sect1 id="sec-performance-tips">
      <title>Performance Tips</title>

      <para>How to make your parser go faster:</para>
      
      <itemizedlist>

	<listitem>
	  <indexterm>
	    <primary>ghc</primary>
	  </indexterm>
	  <para> If you are using GHC, generate parsers using the
          <literal/-g/ option, and compile them using ghc with the
          <literal/-fglasgow-exts/ option.  This is worth about
          10-20%.  Use the <literal/-c/ option: this is worth at least
          another 10%, in code size, execution time and space
          usage.</para>
	</listitem>

	<listitem>
	  <para> The lexical analyser is usually the most performance
          critical part of a parser, so it's worth spending some time
          optimising this.  Profiling tools are essential here.  In
          really dire circumstances, resort to some of the hacks that
          are used in the Glasgow Haskell Compiler's interface-file
          lexer.</para>
	</listitem>

	<listitem>
	  <para> Simplify the grammar as much as possible, as this
          reduces the number of states and reduction rules that need
          to be applied.</para>
	</listitem>

	<listitem>
	  <indexterm>
	    <primary>recursion, left vs. right</primary>
	  </indexterm>
	  <para> Use left recursion rather than right recursion
          wherever possible.  While not strictly a performance issue,
          this affects the size of the parser stack, which is kept on
          the heap and thus needs to be garbage collected.</para>
	</listitem>

      </itemizedlist>


    </sect1>
    
    <sect1 id="sec-compilation-time">
      <title>Compilation-Time Tips</title>

      <para>We have found that compiling parsers generated by
      <application/Happy/ can take a large amount of time/memory, so
      here's some tips on making things more sensible:</para>

      <itemizedlist>

	<listitem>
	  <para> Include as little code as possible in the module
          trailer.  This code is included verbatim in the generated
          parser, so if any of it can go in a separate module, do
          so.</para>
	</listitem>

	<listitem>
	  <indexterm>
	    <primary>type</primary>
	    <secondary>signatures in grammar</secondary>
	  </indexterm>
	  <para> Give type signatures for everything (see <xref
          linkend="sec-type-signatures">.  This is reported to improve
          things by about 50%.  If there is a type signature for every
          single non-terminal in the grammar, then <application/Happy/
          automatically generates type signatures for most functions
          in the parser.</para>
	</listitem>

	<listitem>
	  <para> Simplify the grammar as much as possible (applies to
          everything, this one).</para>
	</listitem>

	<listitem>
	  <para> Use a recent version of GHC.  Versions from 4.04
	  onwards have lower memory requirements for compiling
	  <application/Happy/-generated parsers.</para>
	</listitem>

	<listitem>
	  <para> Using <application/Happy/'s <literal/-g/ option when
	  generating parsers to be compiled with GHC will help
	  considerably.</para>
	</listitem>

      </itemizedlist>

    </sect1>
    
    <sect1 id="sec-finding-errors">
      <title>Finding Type Errors</title>

      <indexterm>
	<primary>type</primary>
	<secondary>errors, finding</secondary>
      </indexterm>

      <para>Finding type errors in grammar files is inherently
      difficult because the code for reductions is moved around before
      being placed in the parser.  We currently have no way of passing
      the original filename and line numbers to the Haskell compiler,
      so there is no alternative but to look at the parser and match
      the code to the grammar file.  An info file (generated by the
      <literal/-i/ option) can be helpful here.</para>

      <indexterm>
	<primary>type</primary>
	<secondary>signatures in grammar</secondary>
      </indexterm>

      <para>Type signature sometimes help by pinning down the
      particular error to the place where the mistake is made, not
      half way down the file.  For each production in the grammar,
      there's a bit of code in the generated file that looks like
      this:</para>

<programlisting>
HappyAbsSyn&lt;n&gt; ( E )
</programlisting>
      <indexterm>
	<primary><literal>HappyAbsSyn</></primary>
      </indexterm>

      <para>where <literal/E/ is the Haskell expression from the
      grammar file (with <literal/&dollar;n/ replaced by
      <literal/happy_var_n/).  If there is a type signature for this
      production, then <application/Happy/ will have taken it into
      account when declaring the HappyAbsSyn datatype, and errors in
      <literal/E/ will be caught right here.  Of course, the error may
      be really caused by incorrect use of one of the
      <literal/happy_var_n/ variables.</para>

      <para>(this section will contain more info as we gain experience
      with creating grammar files.  Please send us any helpful tips
      you find.)</para>

    </sect1>

    <sect1 id="sec-conflict-tips">
      <title>Conflict Tips</title>
      <indexterm>
	<primary>conflicts</primary>
      </indexterm>
      
      <para>Conflicts arise from ambiguities in the grammar.  That is,
      some input sequences may possess more than one parse.
      Shift/reduce conflicts are benign in the sense that they are
      easily resolved (<application/Happy/ automatically selects the
      shift action, as this is usually the intended one).
      Reduce/reduce conflicts are more serious.  A reduce/reduce
      conflict implies that a certain sequence of tokens on the input
      can represent more than one non-terminal, and the parser is
      uncertain as to which reduction rule to use.  It will select the
      reduction rule uppermost in the grammar file, so if you really
      must have a reduce/reduce conflict you can select which rule
      will be used by putting it first in your grammar file.</para>

      <para>It is usually possible to remove conflicts from the
      grammar, but sometimes this is at the expense of clarity and
      simplicity.  Here is a cut-down example from the grammar of
      Haskell (1.2):</para>

<programlisting>
exp     : exp op exp0
        | exp0

exp0    : if exp then exp else exp
        ...
        | atom

atom    : var
        | integer
        | '(' exp ')'
        ...
</programlisting>

      <para>This grammar has a shift/reduce conflict, due to the
      following ambiguity.  In an input such as</para>

<programlisting>
if 1 then 2 else 3 + 4
</programlisting>

      <para>the grammar doesn't specify whether the parse should be</para>

<programlisting>
if 1 then 2 else (3 + 4)
</programlisting>

      <para>or</para>

<programlisting>
(if 1 then 2 else 3) + 4
</programlisting>

      <para>and the ambiguity shows up as a shift/reduce conflict on
      reading the 'op' symbol.  In this case, the first parse is the
      intended one (the 'longest parse' rule), which corresponds to
      the shift action.  Removing this conflict relies on noticing
      that the expression on the left-hand side of an infix operator
      can't be an <literal/exp0/ (the grammar previously said
      otherwise, but since the conflict was resolved as shift, this
      parse was not allowed).  We can reformulate the <literal/exp/
      rule as:</para>

<programlisting>
exp     : atom op exp
        | exp0
</programlisting>

      <para>and this removes the conflict, but at the expense of some
      stack space while parsing (we turned a left-recursion into a
      right-recursion).  There are alternatives using left-recursion,
      but they all involve adding extra states to the parser, so most
      programmers will prefer to keep the conflict in favour of a
      clearer and more efficient parser.</para>

      <sect2 id="sec-lalr">
	<title>LALR(1) parsers</title>

	<para>There are three basic ways to build a shift-reduce
        parser.  Full LR(1) (the `L' is the direction in which the
        input is scanned, the `R' is the way in which the parse is
        built, and the `1' is the number of tokens of lookahead)
        generates a parser with many states, and is therefore large
        and slow.  SLR(1) (simple LR(1)) is a cut-down version of
        LR(1) which generates parsers with roughly one-tenth as many
        states, but lacks the power to parse many grammars (it finds
        conflicts in grammars which have none under LR(1)). </para>

	<para>LALR(1) (look-ahead LR(1)), the method used by
        <application/Happy/ and <application/yacc/, is tradeoff
        between the two.  An LALR(1) parser has the same number of
        states as an SLR(1) parser, but it uses a more complex method
        to calculate the lookahead tokens that are valid at each
        point, and resolves many of the conflicts that SLR(1) finds.
        However, there may still be conflicts in an LALR(1) parser
        that wouldn't be there with full LR(1).</para>

      </sect2>
    </sect1>
  </chapter>

  &the-index

</book>

